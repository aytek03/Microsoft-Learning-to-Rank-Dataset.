{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nw38KAbDKSOm"
   },
   "source": [
    "Welcome to the Learning to Rank\n",
    "Example 2\n",
    "\n",
    "Microsoft Learning to Rank Dataset.\n",
    "\n",
    "\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;LTR Intro http://times.cs.uiuc.edu/course/598f14/l2r.pdf (overview/introduction to Learning to Rank - 2011)<br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;TFR https://arxiv.org/abs/1812.00073 (a specific implementation/framework for Learning to Rank models - 2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKrjg_MS-5_t"
   },
   "source": [
    "# The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pdtz-fNP-eq7"
   },
   "source": [
    "### 1) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vQbF5lfeQ7B-"
   },
   "outputs": [],
   "source": [
    "# Import dependencies here\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_ranking as tfr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1am1Iv_LWR2W"
   },
   "source": [
    "### 2) Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "p_4tmowxOHAF"
   },
   "outputs": [],
   "source": [
    "# Download the dataset located at https://storage.googleapis.com/personalization-takehome/MSLR-WEB10K.zip\n",
    "# You can read about the features included in the dataset here: https://www.microsoft.com/en-us/research/project/mslr/\n",
    "ds = tfds.load(\"mslr_web/10k_fold1\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQdKuIDNWVb8"
   },
   "source": [
    "### 3) Preprocess and evaluate the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WHEqbC9sOrvb"
   },
   "outputs": [],
   "source": [
    "# Preprocess and evaluate the dataset\n",
    "#ds\n",
    "\n",
    "#df = tfds.as_dataframe(ds.take(10))\n",
    "df = tfds.as_dataframe(ds) # dataframe ye Ã§evirdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bm25_anchor</th>\n",
       "      <th>bm25_body</th>\n",
       "      <th>bm25_title</th>\n",
       "      <th>bm25_url</th>\n",
       "      <th>bm25_whole_document</th>\n",
       "      <th>boolean_model_anchor</th>\n",
       "      <th>boolean_model_body</th>\n",
       "      <th>boolean_model_title</th>\n",
       "      <th>boolean_model_url</th>\n",
       "      <th>boolean_model_whole_document</th>\n",
       "      <th>...</th>\n",
       "      <th>variance_of_tf_idf_anchor</th>\n",
       "      <th>variance_of_tf_idf_body</th>\n",
       "      <th>variance_of_tf_idf_title</th>\n",
       "      <th>variance_of_tf_idf_url</th>\n",
       "      <th>variance_of_tf_idf_whole_document</th>\n",
       "      <th>vector_space_model_anchor</th>\n",
       "      <th>vector_space_model_body</th>\n",
       "      <th>vector_space_model_title</th>\n",
       "      <th>vector_space_model_url</th>\n",
       "      <th>vector_space_model_whole_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[29.42768, 9.288441, 18.526854, 0.0, 18.957465...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 11.846837, 0.0, 0.0,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 7.998056, 0.0, 0.0, ...</td>\n",
       "      <td>[28.927591, 9.288662, 18.490218, 0.0, 18.95132...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[27.840805, 19.929322, 36.308397, 0.0, 27.5398...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 44.544215, 0.0, 0.0,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 44.035199, 0.0, 0.0,...</td>\n",
       "      <td>[27.841789, 19.918075, 36.308397, 0.0, 27.5418...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.933903, 0.325014, 0.875523, 0.0, 0.945709, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.761123, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.745211, 0.0, 0.0, ...</td>\n",
       "      <td>[0.933988, 0.324964, 0.875633, 0.0, 0.945726, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 9.997904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[36.243178, 24.041161, 35.895516, 40.150412, 4...</td>\n",
       "      <td>[9.428295, 7.181888, 27.228748, 24.879653, 24....</td>\n",
       "      <td>[7.812148, 0.0, 23.955459, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[36.497524, 24.591495, 36.488682, 40.325685, 4...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 9.003951, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[339.055495, 31.415201, 3305.919844, 1285.5990...</td>\n",
       "      <td>[7.687248, 7.687248, 14.848784, 14.848784, 14....</td>\n",
       "      <td>[9.020905, 0.0, 17.631846, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[417.968267, 64.96175, 3836.19764, 1452.90327,...</td>\n",
       "      <td>[0.0, 0.408501, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.8083, 0.679002, 0.827916, 0.84103, 0.839974...</td>\n",
       "      <td>[0.417303, 0.417303, 0.789509, 0.789509, 0.789...</td>\n",
       "      <td>[0.412937, 0.0, 0.795755, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.783515, 0.606861, 0.829137, 0.840663, 0.839...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 31.099175, 30.484913, 31.105763, 0.0, 22...</td>\n",
       "      <td>[0.0, 28.65454, 28.65454, 16.023471, 0.0, 13.4...</td>\n",
       "      <td>[0.0, 22.842047, 22.842047, 19.6778, 0.0, 0.0,...</td>\n",
       "      <td>[0.0, 33.156394, 32.988977, 32.236219, 0.0, 22...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, ...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 1.228711, 2.72403, 2.764601, 0.0, 292.25...</td>\n",
       "      <td>[0.0, 0.064654, 0.064654, 0.016164, 0.0, 19.50...</td>\n",
       "      <td>[0.0, 0.043984, 0.043984, 0.043984, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 3.770071, 0.667559, 4.924175, 0.0, 383.1...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.989758, 1.0, 0.0, 0.764901, 0.999...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 0.0, 0.697006, 1.0, 0.0, ...</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.691259, 0.0, ...</td>\n",
       "      <td>[0.0, 1.0, 0.997039, 1.0, 0.0, 0.755015, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[12.288321, 13.075652, 12.605294, 15.993784, 1...</td>\n",
       "      <td>[7.69312, 9.684237, 11.621084, 4.758204, 10.59...</td>\n",
       "      <td>[8.196643, 8.196643, 0.0, 8.695295, 8.196643, ...</td>\n",
       "      <td>[14.136543, 13.76887, 13.591888, 16.030504, 16...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[23.545009, 288.426363, 147.156307, 8058.27939...</td>\n",
       "      <td>[18.508313, 18.508313, 74.03325, 18.508313, 18...</td>\n",
       "      <td>[22.635226, 22.635226, 0.0, 22.635226, 22.6352...</td>\n",
       "      <td>[94.160557, 476.687818, 288.366705, 8951.13792...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.264399, 0.264399, 0.264399, 0.264399, 0.264...</td>\n",
       "      <td>[0.436652, 0.436652, 0.436652, 0.436652, 0.436...</td>\n",
       "      <td>[0.47293, 0.47293, 0.0, 0.47293, 0.47293, 0.47...</td>\n",
       "      <td>[0.264374, 0.264374, 0.264374, 0.264374, 0.264...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[27.88085, 0.0, 28.833058, 14.801772, 0.0, 11....</td>\n",
       "      <td>[42.103867, 38.373132, 43.194869, 36.933612, 4...</td>\n",
       "      <td>[28.110139, 19.193686, 33.732166, 22.108442, 3...</td>\n",
       "      <td>[0.0, 0.0, 27.622547, 20.344219, 26.038466, 9....</td>\n",
       "      <td>[42.451466, 38.582556, 43.651186, 38.617481, 4...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[13.69384, 0.0, 1.892948, 14.273079, 0.0, 14.2...</td>\n",
       "      <td>[10240.249987, 407.423062, 798.105042, 13405.8...</td>\n",
       "      <td>[6.715774, 11.835504, 26.863096, 13.222567, 30...</td>\n",
       "      <td>[0.0, 0.0, 1.751718, 50.328568, 1.751718, 14.2...</td>\n",
       "      <td>[10990.6939, 475.568154, 1290.993942, 14438.21...</td>\n",
       "      <td>[0.93639, 0.0, 1.0, 0.555718, 0.0, 0.555718, 0...</td>\n",
       "      <td>[0.952431, 0.893485, 0.992766, 0.703059, 0.971...</td>\n",
       "      <td>[1.0, 0.811025, 1.0, 0.8548, 0.968685, 0.61367...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.754014, 1.0, 0.568278, 0.568...</td>\n",
       "      <td>[0.956585, 0.885813, 0.995693, 0.731488, 0.975...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         bm25_anchor  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 9.997904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [27.88085, 0.0, 28.833058, 14.801772, 0.0, 11....   \n",
       "\n",
       "                                           bm25_body  \\\n",
       "0  [29.42768, 9.288441, 18.526854, 0.0, 18.957465...   \n",
       "1  [36.243178, 24.041161, 35.895516, 40.150412, 4...   \n",
       "2  [0.0, 31.099175, 30.484913, 31.105763, 0.0, 22...   \n",
       "3  [12.288321, 13.075652, 12.605294, 15.993784, 1...   \n",
       "4  [42.103867, 38.373132, 43.194869, 36.933612, 4...   \n",
       "\n",
       "                                          bm25_title  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 11.846837, 0.0, 0.0,...   \n",
       "1  [9.428295, 7.181888, 27.228748, 24.879653, 24....   \n",
       "2  [0.0, 28.65454, 28.65454, 16.023471, 0.0, 13.4...   \n",
       "3  [7.69312, 9.684237, 11.621084, 4.758204, 10.59...   \n",
       "4  [28.110139, 19.193686, 33.732166, 22.108442, 3...   \n",
       "\n",
       "                                            bm25_url  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 7.998056, 0.0, 0.0, ...   \n",
       "1  [7.812148, 0.0, 23.955459, 0.0, 0.0, 0.0, 0.0,...   \n",
       "2  [0.0, 22.842047, 22.842047, 19.6778, 0.0, 0.0,...   \n",
       "3  [8.196643, 8.196643, 0.0, 8.695295, 8.196643, ...   \n",
       "4  [0.0, 0.0, 27.622547, 20.344219, 26.038466, 9....   \n",
       "\n",
       "                                 bm25_whole_document  \\\n",
       "0  [28.927591, 9.288662, 18.490218, 0.0, 18.95132...   \n",
       "1  [36.497524, 24.591495, 36.488682, 40.325685, 4...   \n",
       "2  [0.0, 33.156394, 32.988977, 32.236219, 0.0, 22...   \n",
       "3  [14.136543, 13.76887, 13.591888, 16.030504, 16...   \n",
       "4  [42.451466, 38.582556, 43.651186, 38.617481, 4...   \n",
       "\n",
       "                                boolean_model_anchor  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                  boolean_model_body  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, ...   \n",
       "\n",
       "                                 boolean_model_title  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, ...   \n",
       "\n",
       "                                   boolean_model_url  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                        boolean_model_whole_document  ...  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  ...   \n",
       "2  [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, ...  ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  ...   \n",
       "4  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, ...  ...   \n",
       "\n",
       "                           variance_of_tf_idf_anchor  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 9.003951, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [13.69384, 0.0, 1.892948, 14.273079, 0.0, 14.2...   \n",
       "\n",
       "                             variance_of_tf_idf_body  \\\n",
       "0  [27.840805, 19.929322, 36.308397, 0.0, 27.5398...   \n",
       "1  [339.055495, 31.415201, 3305.919844, 1285.5990...   \n",
       "2  [0.0, 1.228711, 2.72403, 2.764601, 0.0, 292.25...   \n",
       "3  [23.545009, 288.426363, 147.156307, 8058.27939...   \n",
       "4  [10240.249987, 407.423062, 798.105042, 13405.8...   \n",
       "\n",
       "                            variance_of_tf_idf_title  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 44.544215, 0.0, 0.0,...   \n",
       "1  [7.687248, 7.687248, 14.848784, 14.848784, 14....   \n",
       "2  [0.0, 0.064654, 0.064654, 0.016164, 0.0, 19.50...   \n",
       "3  [18.508313, 18.508313, 74.03325, 18.508313, 18...   \n",
       "4  [6.715774, 11.835504, 26.863096, 13.222567, 30...   \n",
       "\n",
       "                              variance_of_tf_idf_url  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 44.035199, 0.0, 0.0,...   \n",
       "1  [9.020905, 0.0, 17.631846, 0.0, 0.0, 0.0, 0.0,...   \n",
       "2  [0.0, 0.043984, 0.043984, 0.043984, 0.0, 0.0, ...   \n",
       "3  [22.635226, 22.635226, 0.0, 22.635226, 22.6352...   \n",
       "4  [0.0, 0.0, 1.751718, 50.328568, 1.751718, 14.2...   \n",
       "\n",
       "                   variance_of_tf_idf_whole_document  \\\n",
       "0  [27.841789, 19.918075, 36.308397, 0.0, 27.5418...   \n",
       "1  [417.968267, 64.96175, 3836.19764, 1452.90327,...   \n",
       "2  [0.0, 3.770071, 0.667559, 4.924175, 0.0, 383.1...   \n",
       "3  [94.160557, 476.687818, 288.366705, 8951.13792...   \n",
       "4  [10990.6939, 475.568154, 1290.993942, 14438.21...   \n",
       "\n",
       "                           vector_space_model_anchor  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.408501, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.93639, 0.0, 1.0, 0.555718, 0.0, 0.555718, 0...   \n",
       "\n",
       "                             vector_space_model_body  \\\n",
       "0  [0.933903, 0.325014, 0.875523, 0.0, 0.945709, ...   \n",
       "1  [0.8083, 0.679002, 0.827916, 0.84103, 0.839974...   \n",
       "2  [0.0, 1.0, 0.989758, 1.0, 0.0, 0.764901, 0.999...   \n",
       "3  [0.264399, 0.264399, 0.264399, 0.264399, 0.264...   \n",
       "4  [0.952431, 0.893485, 0.992766, 0.703059, 0.971...   \n",
       "\n",
       "                            vector_space_model_title  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.761123, 0.0, 0.0, ...   \n",
       "1  [0.417303, 0.417303, 0.789509, 0.789509, 0.789...   \n",
       "2  [0.0, 1.0, 1.0, 1.0, 0.0, 0.697006, 1.0, 0.0, ...   \n",
       "3  [0.436652, 0.436652, 0.436652, 0.436652, 0.436...   \n",
       "4  [1.0, 0.811025, 1.0, 0.8548, 0.968685, 0.61367...   \n",
       "\n",
       "                              vector_space_model_url  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.745211, 0.0, 0.0, ...   \n",
       "1  [0.412937, 0.0, 0.795755, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.691259, 0.0, ...   \n",
       "3  [0.47293, 0.47293, 0.0, 0.47293, 0.47293, 0.47...   \n",
       "4  [0.0, 0.0, 1.0, 0.754014, 1.0, 0.568278, 0.568...   \n",
       "\n",
       "                   vector_space_model_whole_document  \n",
       "0  [0.933988, 0.324964, 0.875633, 0.0, 0.945726, ...  \n",
       "1  [0.783515, 0.606861, 0.829137, 0.840663, 0.839...  \n",
       "2  [0.0, 1.0, 0.997039, 1.0, 0.0, 0.755015, 1.0, ...  \n",
       "3  [0.264374, 0.264374, 0.264374, 0.264374, 0.264...  \n",
       "4  [0.956585, 0.885813, 0.995693, 0.731488, 0.975...  \n",
       "\n",
       "[5 rows x 137 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow_datasets.core.as_dataframe.StyledDataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.map(lambda feature_map: {\n",
    "    \"_mask\": tf.ones_like(feature_map[\"label\"], dtype=tf.bool),\n",
    "    **feature_map\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.shuffle(buffer_size=1000).padded_batch(batch_size=32)\n",
    "ds = ds.map(lambda feature_map: (\n",
    "    feature_map, tf.where(feature_map[\"_mask\"], feature_map.pop(\"label\"), -1.)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OICi0aAuWclQ"
   },
   "source": [
    "### 4) Build ranking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model\n",
    "inputs = {\n",
    "    name: tf.keras.Input(shape=(None, 1), dtype=tf.float32, name=name)\n",
    "    for name in ds.element_spec[0]\n",
    "    if name != \"_mask\"\n",
    "}\n",
    "norm_inputs = [tf.keras.layers.BatchNormalization()(x) for x in inputs.values()]\n",
    "x = tf.concat(norm_inputs, axis=-1)\n",
    "for layer_width in [128, 64, 32]:\n",
    "  x = tf.keras.layers.Dense(units=layer_width)(x)\n",
    "  x = tf.keras.layers.Activation(activation=tf.nn.relu)(x)\n",
    "scores = tf.squeeze(tf.keras.layers.Dense(units=1)(x), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "frHrBKmTSUsq"
   },
   "outputs": [],
   "source": [
    "# Build ranking model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BBtVqWRSWx_g"
   },
   "source": [
    "### 5) Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FpaP8jesTQMj"
   },
   "outputs": [],
   "source": [
    "# Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\pytorchenv\\lib\\site-packages\\keras\\engine\\functional.py:559: UserWarning: Input dict contained keys ['_mask'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 63s 174ms/step - loss: 397.5691 - NDCG@5: 0.3488\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 37s 177ms/step - loss: 396.0957 - NDCG@5: 0.3904\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 37s 177ms/step - loss: 395.8773 - NDCG@5: 0.3990\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 38s 178ms/step - loss: 395.6959 - NDCG@5: 0.4076\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 37s 177ms/step - loss: 395.5662 - NDCG@5: 0.4075\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 38s 182ms/step - loss: 395.4335 - NDCG@5: 0.4103\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 45s 210ms/step - loss: 395.3793 - NDCG@5: 0.4108\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 43s 198ms/step - loss: 395.2766 - NDCG@5: 0.4141\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 41s 194ms/step - loss: 395.1674 - NDCG@5: 0.4163\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 41s 192ms/step - loss: 395.1909 - NDCG@5: 0.4162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x286a634b9b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs=inputs, outputs=scores)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    loss=tfr.keras.losses.SoftmaxLoss(),\n",
    "    metrics=tfr.keras.metrics.get(\"ndcg\", topn=5, name=\"NDCG@5\"))\n",
    "model.fit(ds, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "188/188 [==============================] - 65s 225ms/step - loss: 395.2119 - NDCG@1: 0.4095\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 51s 235ms/step - loss: 395.1156 - NDCG@1: 0.4134\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 53s 242ms/step - loss: 395.0468 - NDCG@1: 0.4219\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 52s 241ms/step - loss: 394.9966 - NDCG@1: 0.4254\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 53s 243ms/step - loss: 394.8727 - NDCG@1: 0.4215\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 53s 243ms/step - loss: 394.8618 - NDCG@1: 0.4227\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 53s 245ms/step - loss: 394.8485 - NDCG@1: 0.4236\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 54s 249ms/step - loss: 394.8400 - NDCG@1: 0.4174\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 53s 247ms/step - loss: 394.7988 - NDCG@1: 0.4205\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 55s 253ms/step - loss: 394.7788 - NDCG@1: 0.4172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x286da4d1160>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = tf.keras.Model(inputs=inputs, outputs=scores)\n",
    "model2.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    loss=tfr.keras.losses.SoftmaxLoss(),\n",
    "    metrics=tfr.keras.metrics.get(\"ndcg\", topn=1, name=\"NDCG@1\"))\n",
    "model2.fit(ds, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\pytorchenv\\lib\\site-packages\\keras\\engine\\functional.py:559: UserWarning: Input dict contained keys ['_mask'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 68s 255ms/step - loss: 394.7465 - mrr_metric: 0.8261\n",
      "Epoch 2/10\n",
      "188/188 [==============================] - 59s 270ms/step - loss: 394.7472 - mrr_metric: 0.8247\n",
      "Epoch 3/10\n",
      "188/188 [==============================] - 60s 275ms/step - loss: 394.6436 - mrr_metric: 0.8255\n",
      "Epoch 4/10\n",
      "188/188 [==============================] - 60s 276ms/step - loss: 394.6175 - mrr_metric: 0.8250\n",
      "Epoch 5/10\n",
      "188/188 [==============================] - 60s 278ms/step - loss: 394.6098 - mrr_metric: 0.8266\n",
      "Epoch 6/10\n",
      "188/188 [==============================] - 61s 279ms/step - loss: 394.6085 - mrr_metric: 0.8279\n",
      "Epoch 7/10\n",
      "188/188 [==============================] - 61s 279ms/step - loss: 394.5769 - mrr_metric: 0.8239\n",
      "Epoch 8/10\n",
      "188/188 [==============================] - 61s 281ms/step - loss: 394.5893 - mrr_metric: 0.8280\n",
      "Epoch 9/10\n",
      "188/188 [==============================] - 62s 283ms/step - loss: 394.5627 - mrr_metric: 0.8288\n",
      "Epoch 10/10\n",
      "188/188 [==============================] - 62s 282ms/step - loss: 394.5421 - mrr_metric: 0.8257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x287157e7fd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = tf.keras.Model(inputs=inputs, outputs=scores)\n",
    "model3.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    loss=tfr.keras.losses.SoftmaxLoss(),\n",
    "    metrics=tfr.keras.metrics.get(tfr.keras.metrics.RankingMetricKey.MRR))\n",
    "model3.fit(ds, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(input_filename, out_data_filename, out_query_filename, out_query_filename2):\n",
    "    input = open(input_filename,\"r\")\n",
    "    output_feature = open(out_data_filename,\"w\")\n",
    "    output_query = open(out_query_filename,\"w\")\n",
    "    output_query2 = open(out_query_filename2,\"w\")\n",
    "    cur_cnt = 0\n",
    "    cur_doc_cnt = 0\n",
    "    last_qid = -1\n",
    "    while True:\n",
    "        line = input.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        tokens = line.split(' ')\n",
    "        tokens[-1] = tokens[-1].strip()\n",
    "        label = tokens[0]\n",
    "        qid = int(tokens[1].split(':')[1])\n",
    "        if qid != last_qid:\n",
    "            if cur_doc_cnt > 0:\n",
    "                output_query.write(str(cur_doc_cnt) + '\\n')\n",
    "                output_query2.write(str(cur_doc_cnt) + '\\n')\n",
    "                cur_cnt += 1\n",
    "            cur_doc_cnt = 0\n",
    "            last_qid = qid\n",
    "        cur_doc_cnt += 1\n",
    "        output_feature.write(label+' ')\n",
    "        output_feature.write(' '.join(tokens[2:]) + '\\n')\n",
    "    output_query.write(str(cur_doc_cnt) + '\\n')\n",
    "    output_query2.write(str(cur_doc_cnt) + '\\n')\n",
    "    \n",
    "    input.close()\n",
    "    output_query.close()\n",
    "    output_feature.close()\n",
    "    output_query2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert(\"train.txt\",\"msltr.train\",\"msltr.train.query\",\"msltr.train.group\")\n",
    "convert(\"test.txt\",\"msltr.test\",\"msltr.test.query\",\"msltr.test.group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Loading query boundaries...\n",
      "[LightGBM] [Info] Construct bin mappers from text data time 6.06 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.179079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 25637\n",
      "[LightGBM] [Info] Number of data points in the train set: 723412, number of used features: 136\n",
      "[LightGBM] [Info] Loading query boundaries...\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid's ndcg@1: 0.449857\tvalid's ndcg@3: 0.4424\tvalid's ndcg@5: 0.44547\tvalid's ndcg@10: 0.463682\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid's ndcg@1: 0.466686\tvalid's ndcg@3: 0.457343\tvalid's ndcg@5: 0.4608\tvalid's ndcg@10: 0.478975\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid's ndcg@1: 0.48081\tvalid's ndcg@3: 0.466484\tvalid's ndcg@5: 0.470233\tvalid's ndcg@10: 0.487116\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid's ndcg@1: 0.47999\tvalid's ndcg@3: 0.473039\tvalid's ndcg@5: 0.476394\tvalid's ndcg@10: 0.491428\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid's ndcg@1: 0.485319\tvalid's ndcg@3: 0.475528\tvalid's ndcg@5: 0.478571\tvalid's ndcg@10: 0.495003\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Note that we have convert the original raw data into a pure libsvm format.\n",
    "# For more details, pls refer to: https://github.com/guolinke/boosting_tree_benchmarks/tree/master/data\n",
    "infile_train = \"msltr.train\"\n",
    "infile_valid = \"msltr.test\"\n",
    "\n",
    "train_data = lgb.Dataset(infile_train)\n",
    "valid_data = lgb.Dataset(infile_valid)\n",
    "\n",
    "# Set group info.\n",
    "#We can igonre the step if *.query files exist with input files in the same dir.\n",
    "train_group_size = [l.strip(\"\\n\") for l in open(infile_train + \".query\")]\n",
    "valid_group_size = [l.strip(\"\\n\") for l in open(infile_valid + \".query\")]\n",
    "train_data.set_group(train_group_size)\n",
    "valid_data.set_group(valid_group_size)\n",
    "\n",
    "# Parameters are borrowed from the official experiment doc:\n",
    "# https://lightgbm.readthedocs.io/en/latest/Experiments.html\n",
    "param = {\n",
    "    \"task\": \"train\",\n",
    "    \"num_leaves\": 255,\n",
    "    \"min_data_in_leaf\": 1,\n",
    "    \"min_sum_hessian_in_leaf\": 100,\n",
    "    \"objective\": \"lambdarank\",\n",
    "    \"metric\": \"ndcg\",\n",
    "    \"ndcg_eval_at\": [1, 3, 5, 10],\n",
    "    \"learning_rate\": .1,\n",
    "    \"num_threads\": 2\n",
    "}\n",
    "\n",
    "res = {}\n",
    "bst = lgb.train(\n",
    "    param, train_data, \n",
    "    valid_sets=[valid_data], valid_names=[\"valid\"],\n",
    "    num_boost_round=50, evals_result=res, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ndcg@1</th>\n",
       "      <th>ndcg@3</th>\n",
       "      <th>ndcg@5</th>\n",
       "      <th>ndcg@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.483229</td>\n",
       "      <td>0.475547</td>\n",
       "      <td>0.478167</td>\n",
       "      <td>0.493541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.481214</td>\n",
       "      <td>0.475276</td>\n",
       "      <td>0.477785</td>\n",
       "      <td>0.493324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.484057</td>\n",
       "      <td>0.475098</td>\n",
       "      <td>0.478074</td>\n",
       "      <td>0.493586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.484762</td>\n",
       "      <td>0.475585</td>\n",
       "      <td>0.478810</td>\n",
       "      <td>0.494662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.485319</td>\n",
       "      <td>0.475528</td>\n",
       "      <td>0.478571</td>\n",
       "      <td>0.495003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ndcg@1    ndcg@3    ndcg@5   ndcg@10\n",
       "45  0.483229  0.475547  0.478167  0.493541\n",
       "46  0.481214  0.475276  0.477785  0.493324\n",
       "47  0.484057  0.475098  0.478074  0.493586\n",
       "48  0.484762  0.475585  0.478810  0.494662\n",
       "49  0.485319  0.475528  0.478571  0.495003"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the eval metric in tabular format.\n",
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(res[\"valid\"]).tail()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "O'Reilly ML Engineer Take Home 2022 adlÄ± not defterinin kopyasÄ±",
   "provenance": [
    {
     "file_id": "1FOjKMwqvL_q_XU2xP5YyFM9WHxAaIBch",
     "timestamp": 1648235636328
    },
    {
     "file_id": "1BPGNDmO2MzdME7Y6_0JMVEu1ZA1TnSzp",
     "timestamp": 1647615671082
    },
    {
     "file_id": "1YMxKUdCtbBHosV93CP5fOoYDvwhbxJHd",
     "timestamp": 1644438116844
    },
    {
     "file_id": "1ESnWcJzqO8ZA2jgkNFAzvgx1I9cdY8Ip",
     "timestamp": 1605711642591
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
